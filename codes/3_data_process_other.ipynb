{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_data_articles_with_sentiment.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_date</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>url</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-28 21:06:10+00:00</td>\n",
       "      <td>FB</td>\n",
       "      <td>US STOCKS SNAPSHOT-Wall St ends up sharply on ...</td>\n",
       "      <td>NEW YORK, Aug 16 (Reuters) - U.S. stocks rebou...</td>\n",
       "      <td>https://www.reuters.com/article/usa-stocks/us-...</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-18 21:05:42+00:00</td>\n",
       "      <td>WMT</td>\n",
       "      <td>US STOCKS SNAPSHOT-S&amp;P, Dow eke out gains afte...</td>\n",
       "      <td>NEW YORK, Sept 6 (Reuters) - The S&amp;P 500 and t...</td>\n",
       "      <td>https://www.reuters.com/article/usa-stocks/us-...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-02 22:09:26+00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>US STOCKS SNAPSHOT-Wall Street ends mixed as M...</td>\n",
       "      <td>Sept 19 (Reuters) - Wall Street ended mixed on...</td>\n",
       "      <td>https://www.reuters.com/article/usa-stocks/us-...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-02 22:09:26+00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>US STOCKS SNAPSHOT-Wall Street ends mixed as M...</td>\n",
       "      <td>Sept 19 (Reuters) - Wall Street ended mixed on...</td>\n",
       "      <td>https://www.reuters.com/article/usa-stocks/us-...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-31 20:05:35+00:00</td>\n",
       "      <td>BA</td>\n",
       "      <td>US STOCKS SNAPSHOT-Boeing, J&amp;J pull down Wall ...</td>\n",
       "      <td>NEW YORK, Oct 18 (Reuters) - Wall Street fell ...</td>\n",
       "      <td>https://www.reuters.com/article/usa-stocks/us-...</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              published_date company  \\\n",
       "0  2016-01-28 21:06:10+00:00      FB   \n",
       "1  2016-02-18 21:05:42+00:00     WMT   \n",
       "2  2016-03-02 22:09:26+00:00    AAPL   \n",
       "3  2016-03-02 22:09:26+00:00    MSFT   \n",
       "4  2016-03-31 20:05:35+00:00      BA   \n",
       "\n",
       "                                               title  \\\n",
       "0  US STOCKS SNAPSHOT-Wall St ends up sharply on ...   \n",
       "1  US STOCKS SNAPSHOT-S&P, Dow eke out gains afte...   \n",
       "2  US STOCKS SNAPSHOT-Wall Street ends mixed as M...   \n",
       "3  US STOCKS SNAPSHOT-Wall Street ends mixed as M...   \n",
       "4  US STOCKS SNAPSHOT-Boeing, J&J pull down Wall ...   \n",
       "\n",
       "                                                body  \\\n",
       "0  NEW YORK, Aug 16 (Reuters) - U.S. stocks rebou...   \n",
       "1  NEW YORK, Sept 6 (Reuters) - The S&P 500 and t...   \n",
       "2  Sept 19 (Reuters) - Wall Street ended mixed on...   \n",
       "3  Sept 19 (Reuters) - Wall Street ended mixed on...   \n",
       "4  NEW YORK, Oct 18 (Reuters) - Wall Street fell ...   \n",
       "\n",
       "                                                 url  compound    neg    neu  \\\n",
       "0  https://www.reuters.com/article/usa-stocks/us-...    0.5423  0.000  0.741   \n",
       "1  https://www.reuters.com/article/usa-stocks/us-...    0.3400  0.000  0.806   \n",
       "2  https://www.reuters.com/article/usa-stocks/us-...    0.0000  0.000  1.000   \n",
       "3  https://www.reuters.com/article/usa-stocks/us-...    0.0000  0.000  1.000   \n",
       "4  https://www.reuters.com/article/usa-stocks/us-...   -0.4404  0.195  0.805   \n",
       "\n",
       "     pos  \n",
       "0  0.259  \n",
       "1  0.194  \n",
       "2  0.000  \n",
       "3  0.000  \n",
       "4  0.000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()\n",
    "df2=pd.DataFrame(df2)\n",
    "n=df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YuNan\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,n):\n",
    "    \n",
    "    df2['published_date'][i]=df2['published_date'][i][0:10]\n",
    "    if i%10000==0:\n",
    "        print(i)\n",
    "df2.to_csv('sentiment.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[15]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FB', 'WMT', 'AAPL', 'MSFT', 'BA', 'JNJ', 'CSCO', 'TSLA', 'AMZN',\n",
       "       'TWTR', 'CVS', 'DIS', 'XOM', 'GS', 'T', 'CME', 'AVGO', 'QCOM',\n",
       "       'NVDA', 'WBA', 'AIG', 'BAC', 'V', 'VZ', 'GOOG', 'GOOGL', 'MAR',\n",
       "       'FDX', 'GE', 'DAL', 'LUV', 'MRK', 'AAL', 'CMCSA', 'GM', 'NKE',\n",
       "       'BIIB', 'TGT', 'MET', 'XRX', 'KR', 'SO', 'PFE', 'IBM', 'JPM',\n",
       "       'PEP', 'TMO', 'CAT', 'WFC', 'UNH', 'EBAY', 'OXY', 'SLB', 'BLK',\n",
       "       'NFLX', 'AMGN', 'TSN', 'LMT', 'COP', 'FCX', 'HPQ', 'MCD', 'KO',\n",
       "       'ABBV', 'TMUS', 'KHC', 'INTC', 'ABT', 'GILD', 'CVX', 'MA', 'LLY',\n",
       "       'CB', 'ALB', 'VLO', 'REGN', 'MPC', 'CBOE', 'UAL', 'F', 'VIAC'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped=df2.groupby(['company']).size()\n",
    "# print(grouped[:50])\n",
    "\n",
    "# BA=df2.groupby(['company']).filter(lambda x: x=='BA')\n",
    "# print(BA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FB'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['company'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1663, 9)\n",
      "(597, 9)\n",
      "(1778, 9)\n",
      "(537, 9)\n",
      "(2234, 9)\n",
      "(593, 9)\n",
      "(110, 9)\n",
      "(1464, 9)\n",
      "(1645, 9)\n",
      "(309, 9)\n",
      "(216, 9)\n",
      "(435, 9)\n",
      "(711, 9)\n",
      "(845, 9)\n",
      "(352, 9)\n",
      "(479, 9)\n",
      "(130, 9)\n",
      "(391, 9)\n",
      "(168, 9)\n",
      "(130, 9)\n",
      "(126, 9)\n",
      "(199, 9)\n",
      "(114, 9)\n",
      "(134, 9)\n",
      "(541, 9)\n",
      "(541, 9)\n",
      "(103, 9)\n",
      "(180, 9)\n",
      "(452, 9)\n",
      "(335, 9)\n",
      "(277, 9)\n",
      "(313, 9)\n",
      "(296, 9)\n",
      "(289, 9)\n",
      "(712, 9)\n",
      "(217, 9)\n",
      "(149, 9)\n",
      "(117, 9)\n",
      "(107, 9)\n",
      "(127, 9)\n",
      "(109, 9)\n",
      "(104, 9)\n",
      "(1607, 9)\n",
      "(191, 9)\n",
      "(587, 9)\n",
      "(107, 9)\n",
      "(103, 9)\n",
      "(114, 9)\n",
      "(379, 9)\n",
      "(104, 9)\n",
      "(130, 9)\n",
      "(190, 9)\n",
      "(105, 9)\n",
      "(367, 9)\n",
      "(369, 9)\n",
      "(168, 9)\n",
      "(119, 9)\n",
      "(241, 9)\n",
      "(144, 9)\n",
      "(108, 9)\n",
      "(103, 9)\n",
      "(217, 9)\n",
      "(133, 9)\n",
      "(228, 9)\n",
      "(307, 9)\n",
      "(111, 9)\n",
      "(323, 9)\n",
      "(122, 9)\n",
      "(402, 9)\n",
      "(388, 9)\n",
      "(142, 9)\n",
      "(162, 9)\n",
      "(129, 9)\n",
      "(108, 9)\n",
      "(102, 9)\n",
      "(189, 9)\n",
      "(107, 9)\n",
      "(289, 9)\n",
      "(123, 9)\n",
      "(300, 9)\n",
      "(183, 9)\n"
     ]
    }
   ],
   "source": [
    "for i in range(df2['company'].unique().shape[0]):\n",
    "    dff1 = df2[df2.company == df2['company'].unique()[i]]\n",
    "    print(dff1.shape)\n",
    "    dff1.to_csv('sentiment\\sentiment_{}.csv'.format(df2['company'].unique()[i]),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2234, 9)\n"
     ]
    }
   ],
   "source": [
    "dff1=df2[(df2.company=='BA')]\n",
    "print(dff1.shape)\n",
    "# dff2=df2[(df2.source_name=='cnbc.com')]\n",
    "# print(dff2.shape)\n",
    "# dff3=df2[(df2.source_name=='fortune.com')]\n",
    "# print(dff3.shape)\n",
    "# dff4=df2[(df2.source_name=='reuters.com')]\n",
    "# print(dff4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 4)\n",
      "(608, 4)\n",
      "(325, 4)\n",
      "(325, 4)\n",
      "(601, 4)\n",
      "(601, 4)\n",
      "(286, 4)\n",
      "(286, 4)\n",
      "(656, 4)\n",
      "(656, 4)\n",
      "(286, 4)\n",
      "(286, 4)\n",
      "(68, 4)\n",
      "(68, 4)\n",
      "(562, 4)\n",
      "(562, 4)\n",
      "(646, 4)\n",
      "(646, 4)\n",
      "(192, 4)\n",
      "(192, 4)\n",
      "(125, 4)\n",
      "(125, 4)\n",
      "(224, 4)\n",
      "(224, 4)\n",
      "(373, 4)\n",
      "(373, 4)\n",
      "(445, 4)\n",
      "(445, 4)\n",
      "(219, 4)\n",
      "(219, 4)\n",
      "(257, 4)\n",
      "(257, 4)\n",
      "(45, 4)\n",
      "(45, 4)\n",
      "(178, 4)\n",
      "(178, 4)\n",
      "(87, 4)\n",
      "(87, 4)\n",
      "(77, 4)\n",
      "(77, 4)\n",
      "(75, 4)\n",
      "(75, 4)\n",
      "(139, 4)\n",
      "(139, 4)\n",
      "(77, 4)\n",
      "(77, 4)\n",
      "(91, 4)\n",
      "(91, 4)\n",
      "(311, 4)\n",
      "(311, 4)\n",
      "(311, 4)\n",
      "(311, 4)\n",
      "(64, 4)\n",
      "(64, 4)\n",
      "(98, 4)\n",
      "(98, 4)\n",
      "(235, 4)\n",
      "(235, 4)\n",
      "(191, 4)\n",
      "(191, 4)\n",
      "(148, 4)\n",
      "(148, 4)\n",
      "(183, 4)\n",
      "(183, 4)\n",
      "(187, 4)\n",
      "(187, 4)\n",
      "(151, 4)\n",
      "(151, 4)\n",
      "(354, 4)\n",
      "(354, 4)\n",
      "(136, 4)\n",
      "(136, 4)\n",
      "(85, 4)\n",
      "(85, 4)\n",
      "(68, 4)\n",
      "(68, 4)\n",
      "(63, 4)\n",
      "(63, 4)\n",
      "(54, 4)\n",
      "(54, 4)\n",
      "(63, 4)\n",
      "(63, 4)\n",
      "(74, 4)\n",
      "(74, 4)\n",
      "(322, 4)\n",
      "(322, 4)\n",
      "(129, 4)\n",
      "(129, 4)\n",
      "(337, 4)\n",
      "(337, 4)\n",
      "(56, 4)\n",
      "(56, 4)\n",
      "(70, 4)\n",
      "(70, 4)\n",
      "(57, 4)\n",
      "(57, 4)\n",
      "(221, 4)\n",
      "(221, 4)\n",
      "(58, 4)\n",
      "(58, 4)\n",
      "(79, 4)\n",
      "(79, 4)\n",
      "(103, 4)\n",
      "(103, 4)\n",
      "(68, 4)\n",
      "(68, 4)\n",
      "(220, 4)\n",
      "(220, 4)\n",
      "(213, 4)\n",
      "(213, 4)\n",
      "(104, 4)\n",
      "(104, 4)\n",
      "(70, 4)\n",
      "(70, 4)\n",
      "(158, 4)\n",
      "(158, 4)\n",
      "(95, 4)\n",
      "(95, 4)\n",
      "(63, 4)\n",
      "(63, 4)\n",
      "(64, 4)\n",
      "(64, 4)\n",
      "(132, 4)\n",
      "(132, 4)\n",
      "(85, 4)\n",
      "(85, 4)\n",
      "(131, 4)\n",
      "(131, 4)\n",
      "(161, 4)\n",
      "(161, 4)\n",
      "(65, 4)\n",
      "(65, 4)\n",
      "(190, 4)\n",
      "(190, 4)\n",
      "(77, 4)\n",
      "(77, 4)\n",
      "(183, 4)\n",
      "(183, 4)\n",
      "(232, 4)\n",
      "(232, 4)\n",
      "(84, 4)\n",
      "(84, 4)\n",
      "(99, 4)\n",
      "(99, 4)\n",
      "(95, 4)\n",
      "(95, 4)\n",
      "(73, 4)\n",
      "(73, 4)\n",
      "(65, 4)\n",
      "(65, 4)\n",
      "(102, 4)\n",
      "(102, 4)\n",
      "(66, 4)\n",
      "(66, 4)\n",
      "(179, 4)\n",
      "(179, 4)\n",
      "(80, 4)\n",
      "(80, 4)\n",
      "(163, 4)\n",
      "(163, 4)\n",
      "(109, 4)\n",
      "(109, 4)\n"
     ]
    }
   ],
   "source": [
    "for i in range(df2['company'].unique().shape[0]):\n",
    "    dff1 = pd.read_csv('sentiment\\sentiment_{}.csv'.format(df2['company'].unique()[i]))\n",
    "    sp = pd.read_csv(\"C:/Users/YuNan/Downloads/stock/historical_price/historical_price/BA_2015-12-30_2021-02-21_minute.csv\")#,index_col=0)\n",
    "    sp=pd.DataFrame(sp)\n",
    "    dff1g=dff1.groupby(['published_date']).agg(['mean'])\n",
    "    print(dff1g.shape)\n",
    "    dff1g=dff1.groupby(['published_date']).agg(['mean'])\n",
    "    print(dff1g.shape)\n",
    "    dff1g.to_csv('groupby\\sentiment_{}_groupby.csv'.format(df2['company'].unique()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FB\n",
      "(1364, 4)\n",
      "WMT\n",
      "(1364, 4)\n",
      "AAPL\n",
      "(1364, 4)\n",
      "MSFT\n",
      "(1364, 4)\n",
      "BA\n",
      "(1364, 4)\n",
      "JNJ\n",
      "(1364, 4)\n",
      "CSCO\n",
      "(1364, 4)\n",
      "TSLA\n",
      "(1364, 4)\n",
      "AMZN\n",
      "(1364, 4)\n",
      "TWTR\n",
      "(1364, 4)\n",
      "CVS\n",
      "(1364, 4)\n",
      "DIS\n",
      "(1364, 4)\n",
      "XOM\n",
      "(1364, 4)\n",
      "GS\n",
      "(1364, 4)\n",
      "T\n",
      "(1364, 4)\n",
      "CME\n",
      "(1364, 4)\n",
      "AVGO\n",
      "(1364, 4)\n",
      "QCOM\n",
      "(1364, 4)\n",
      "NVDA\n",
      "(1364, 4)\n",
      "WBA\n",
      "(1364, 4)\n",
      "AIG\n",
      "(1364, 4)\n",
      "BAC\n",
      "(1364, 4)\n",
      "V\n",
      "(1364, 4)\n",
      "VZ\n",
      "(1364, 4)\n",
      "GOOG\n",
      "(1364, 4)\n",
      "GOOGL\n",
      "(1364, 4)\n",
      "MAR\n",
      "(1364, 4)\n",
      "FDX\n",
      "(1364, 4)\n",
      "GE\n",
      "(1364, 4)\n",
      "DAL\n",
      "(1364, 4)\n",
      "LUV\n",
      "(1364, 4)\n",
      "MRK\n",
      "(1364, 4)\n",
      "AAL\n",
      "(1364, 4)\n",
      "CMCSA\n",
      "(1364, 4)\n",
      "GM\n",
      "(1364, 4)\n",
      "NKE\n",
      "(1364, 4)\n",
      "BIIB\n",
      "(1364, 4)\n",
      "TGT\n",
      "(1364, 4)\n",
      "MET\n",
      "(1364, 4)\n",
      "XRX\n",
      "(1364, 4)\n",
      "KR\n",
      "(1364, 4)\n",
      "SO\n",
      "(1364, 4)\n",
      "PFE\n",
      "(1364, 4)\n",
      "IBM\n",
      "(1364, 4)\n",
      "JPM\n",
      "(1364, 4)\n",
      "PEP\n",
      "(1364, 4)\n",
      "TMO\n",
      "(1364, 4)\n",
      "CAT\n",
      "(1364, 4)\n",
      "WFC\n",
      "(1364, 4)\n",
      "UNH\n",
      "(1364, 4)\n",
      "EBAY\n",
      "(1364, 4)\n",
      "OXY\n",
      "(1364, 4)\n",
      "SLB\n",
      "(1364, 4)\n",
      "BLK\n",
      "(1364, 4)\n",
      "NFLX\n",
      "(1364, 4)\n",
      "AMGN\n",
      "(1364, 4)\n",
      "TSN\n",
      "(1364, 4)\n",
      "LMT\n",
      "(1364, 4)\n",
      "COP\n",
      "(1364, 4)\n",
      "FCX\n",
      "(1364, 4)\n",
      "HPQ\n",
      "(1364, 4)\n",
      "MCD\n",
      "(1364, 4)\n",
      "KO\n",
      "(1364, 4)\n",
      "ABBV\n",
      "(1364, 4)\n",
      "TMUS\n",
      "(1364, 4)\n",
      "KHC\n",
      "(1364, 4)\n",
      "INTC\n",
      "(1364, 4)\n",
      "ABT\n",
      "(1364, 4)\n",
      "GILD\n",
      "(1364, 4)\n",
      "CVX\n",
      "(1364, 4)\n",
      "MA\n",
      "(1364, 4)\n",
      "LLY\n",
      "(1364, 4)\n",
      "CB\n",
      "(1364, 4)\n",
      "ALB\n",
      "(1364, 4)\n",
      "VLO\n",
      "(1364, 4)\n",
      "REGN\n",
      "(1364, 4)\n",
      "MPC\n",
      "(1364, 4)\n",
      "CBOE\n",
      "(1364, 4)\n",
      "UAL\n",
      "(1364, 4)\n",
      "F\n",
      "(1364, 4)\n",
      "VIAC\n",
      "(1364, 4)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for ii in range(df2['company'].unique().shape[0]):\n",
    "    print(df2['company'].unique()[ii])\n",
    "    d1 = pd.read_csv('groupby\\sentiment_{}_groupby.csv'.format(df2['company'].unique()[ii]))\n",
    "    d1 = d1.iloc[3:]\n",
    "\n",
    "    d1.columns =['published_date','compound', 'neg', 'neu', 'pos']\n",
    "    d1.reset_index(drop=True, inplace=True)\n",
    "    sp1=sp.copy()\n",
    "    m=sp.shape[0]\n",
    "#     for i in range (0,3):\n",
    "#         sp1['t'][i].replace('-','/')\n",
    "#     # print(sp1['t'][0])\n",
    "#     sp1['t'][0]==d1['published_date'][0]\n",
    "\n",
    "#     t=d1['published_date'][0]\n",
    "#     print(d1['published_date'][0])\n",
    "#     timeStruct = time.strptime(t, \"%m/%d/%Y\") \n",
    "#     strTime = time.strftime(\"%Y-%m-%d\", timeStruct) \n",
    "#     for i in range(0,d1.shape[0]):\n",
    "#         t=d1['published_date'][i]\n",
    "#         timeStruct = time.strptime(t, \"%m/%d/%Y\") \n",
    "#         d1['published_date'][i] = time.strftime(\"%Y-%m-%d\", timeStruct) \n",
    "    sp1['date'] = sp1['t'].apply(lambda x: x.split(' '))\n",
    "    sp1['Date'] = sp1['date'].apply(lambda x: x[0])\n",
    "    sp1['time'] = sp1['date'].apply(lambda x: x[1])\n",
    "    sp1.drop_duplicates(subset=['Date'], keep='last', inplace = True)\n",
    "    sp1.reset_index(inplace = True)\n",
    "\n",
    "    date_union_1=pd.DataFrame(columns=('idx','date','mean_compound','comp_flag'))\n",
    "    sp_len=sp1.shape[0]\n",
    "    d_len=d1.shape[0]\n",
    "    d=d1.copy()\n",
    "    for i in range(0,sp_len):\n",
    "        idx=i\n",
    "        date=sp1['Date'][i]\n",
    "        j=0\n",
    "        t=0\n",
    "        while j<d_len:\n",
    "            if sp1['Date'][i]==d['published_date'][j]:\n",
    "                mean_compound=d['compound'][j]\n",
    "                comp_flag=1\n",
    "                t=1\n",
    "                break\n",
    "            j=j+1\n",
    "        if t==0:\n",
    "            mean_compound=0\n",
    "            comp_flag=0\n",
    "\n",
    "        date_union_1=date_union_1.append(pd.DataFrame({'idx':[idx],\n",
    "                                                      'date':[date],\n",
    "                                                      'mean_compound':[mean_compound],\n",
    "                                                      'comp_flag':[comp_flag]\n",
    "\n",
    "        }),ignore_index=True)\n",
    "    print(date_union_1.shape)\n",
    "    date_union_1.to_csv('new_data_union_{}.csv'.format(df2['company'].unique()[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_union_1.to_csv('new_date_union_AAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
